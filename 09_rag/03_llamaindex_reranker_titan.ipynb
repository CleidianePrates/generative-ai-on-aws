{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1b23ffc-22d8-4414-b2e4-66d45a03523d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Using LLM-powered retreival and reranking - (Titan LLM + Bedrock Titan embedding)\n",
    "\n",
    "### Context\n",
    "\n",
    "Utilizing LLM-driven retrieval has the potential to yield more pertinent documents compared to retrieval based on embeddings. However, this advantage comes at the expense of increased latency and expenses. We will demonstrate that employing embedding-based retrieval initially, followed by a secondary retrieval stage for reevaluation, can offer a balanced solution.\n",
    "\n",
    "A recent surge in applications involving \"Develop a chatbot using your data\" has emerged in the past several months. This trend has been facilitated by frameworks such as LlamaIndex and LangChain. Many of these applications rely on a standard approach known as retrieval augmented generation (RAG):\n",
    "\n",
    "1) A vector store is employed to store unstructured documents (knowledge corpus).\n",
    "2) When presented with a query, a retrieval model is utilized to fetch relevant documents from the corpus, followed by a synthesis model that generates a response.\n",
    "3) The retrieval model retrieves the top-k documents based on the similarity of their embeddings to the query. It's important to note that the concept of top-k embedding-based semantic search has existed for over a decade and doesn't involve the use of LLM.\n",
    "\n",
    "The utilization of embedding-based retrieval offers numerous advantages:\n",
    "\n",
    "* Dot product calculations are swift and don't necessitate model invocations during query processing.\n",
    "* Although not flawless, embeddings can effectively capture the semantics of documents and queries. There's a subset of queries for which embedding-based retrieval yields highly relevant outcomes.\n",
    "\n",
    "However, embedding-based retrieval can exhibit imprecision and return irrelevant context for the query due to various factors. This subsequently diminishes the quality of the overall RAG system, irrespective of the LLM's quality.\n",
    "\n",
    "Addressing this challenge is not novel; existing information retrieval and recommendation systems have adopted a two-stage approach. The initial stage employs embedding-based retrieval with a higher top-k value to maximize recall while accepting a lower precision. Subsequently, the second stage utilizes a somewhat more computationally intensive process characterized by higher precision and lower recall (such as BM25) to \"rerank\" the initially retrieved candidates.\n",
    "\n",
    "Delving into the shortcomings of embedding-based retrieval would require an entire series of blog posts. This current post serves as an initial exploration of an alternative retrieval technique and its potential to enhance embedding-based retrieval methodologies.\n",
    " \n",
    "![LLM retrival works](./images/arch.png)\n",
    "\n",
    "### LLM Retrieval and Reranking\n",
    "\n",
    "LLM Retrieval and reranking strategy employs the LLM to determine the document(s) or sections of text that align with the provided query. The input prompt comprises a collection of potential documents, and the LLM is entrusted with choosing the pertinent group of documents while also assigning a score to gauge their relevance using an internal measurement.\n",
    "\n",
    "\n",
    "In this notebook we explain how to approach the retriever pattern of LLM-powered retrieval and reranking using Amazon Bedrock LLM and LlamaIndex\n",
    "\n",
    "#### LlamaIndex\n",
    "LlamaIndex is a data framework for your LLM application. It provides the following tools:\n",
    "\n",
    "* Offers data connectors to ingest your existing data sources and data formats (APIs, PDFs, docs, SQL, etc.)\n",
    "* Provides ways to structure your data (indices, graphs) so that this data can be easily used with LLMs.\n",
    "* Provides an advanced retrieval/query interface over your data: Feed in any LLM input prompt, get back retrieved context and knowledge-augmented output.\n",
    "* Allows easy integrations with your outer application framework (e.g. with LangChain, Flask, Docker, anything else).\n",
    "* LlamaIndex provides tools for both beginner users and advanced users. Our high-level API allows beginner users to use LlamaIndex to ingest and query their data in 5 lines of code. Our lower-level APIs allow advanced users to customize and extend any module (data connectors, indices, retrievers, query engines, reranking modules), to fit their needs.\n",
    "\n",
    "### LLM Used:\n",
    "We will be leveraging Bedrock - Anthropic Titan LLM and Bedrock Embedding (Titan model) for demonstration.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f320367c-42b6-46e3-b367-de7327d6e665",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "We will first install the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "074cdec9-58a4-4894-b90e-53170777c673",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./download-dependencies.sh: 2: Bad substitution\n",
      "Existing dependency directory found, removing and replacing...\n",
      "Creating dependency directory\n",
      "Downloading dependencies\n",
      "Unpacking dependencies\n",
      "/usr/bin/unzip\n",
      "Archive:  sdk.zip\n",
      "   creating: reviews/\n",
      "  inflating: awscli-1.29.21.tar.gz   \n",
      "  inflating: AWSCLI32PY3.msi         \n",
      "  inflating: manifest.json           \n",
      "  inflating: AWSCLISetup.exe         \n",
      "  inflating: .functional             \n",
      "  inflating: awscli-bundle.zip       \n",
      "  inflating: boto3-1.28.21-py3-none-any.whl  \n",
      "  inflating: models-starfort-report.json  \n",
      "  inflating: .unit                   \n",
      "  inflating: AWSCLI32.msi            \n",
      "  inflating: .unit-crt               \n",
      "  inflating: AWSCLI64PY3.msi         \n",
      "  inflating: boto3-1.28.21.tar.gz    \n",
      "  inflating: .functional-crt         \n",
      "  inflating: AWSCLI64.msi            \n",
      "  inflating: botocore-1.31.21.tar.gz  \n",
      "  inflating: awscli-1.29.21-py3-none-any.whl  \n",
      "  inflating: botocore-1.31.21-py3-none-any.whl  \n",
      "  inflating: reviews/awscli-1.29.21.diff  \n",
      "  inflating: reviews/botocore-1.31.21.diff  \n",
      "  inflating: reviews/awscli-1.29.21.html  \n",
      "  inflating: reviews/boto3-1.28.21.commits  \n",
      "  inflating: reviews/botocore-1.31.21.html  \n",
      "  inflating: reviews/botocore-1.31.21.commits  \n",
      "  inflating: reviews/boto3-1.28.21.html  \n",
      "  inflating: reviews/awscli-1.29.21.commits  \n",
      "  inflating: reviews/boto3-1.28.21.diff  \n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "!cd .. && ./download-dependencies.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44150464-2078-4c67-8dc2-e485df8f55f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Popen: returncode: None args: ['pip', 'install', '../dependencies/botocore-...>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import subprocess\n",
    "\n",
    "botocore_whl_filename = glob.glob(\"../dependencies/botocore-*-py3-none-any.whl\")[0]\n",
    "boto3_whl_filename = glob.glob(\"../dependencies/boto3-*-py3-none-any.whl\")[0]\n",
    "\n",
    "subprocess.Popen(['pip', 'install', botocore_whl_filename, boto3_whl_filename, '--force-reinstall'], bufsize=1, universal_newlines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f52c0cec-b59c-4c69-9e79-6979d0e758ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /root/amazon-bedrock-rag/dependencies/botocore-1.31.21-py3-none-any.whl\n",
      "Processing /root/amazon-bedrock-rag/dependencies/boto3-1.28.21-py3-none-any.whl\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from botocore==1.31.21)\n",
      "  Using cached jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Collecting python-dateutil<3.0.0,>=2.1 (from botocore==1.31.21)\n",
      "  Using cached python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
      "Collecting pydantic==1.10.12\n",
      "  Obtaining dependency information for pydantic==1.10.12 from https://files.pythonhosted.org/packages/bc/e0/0371e9b6c910afe502e5fe18cc94562bfd9399617c7b4f5b6e13c29115b3/pydantic-1.10.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached pydantic-1.10.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (149 kB)\n",
      "Collecting urllib3<1.27,>=1.25.4 (from botocore==1.31.21)\n",
      "  Obtaining dependency information for urllib3<1.27,>=1.25.4 from https://files.pythonhosted.org/packages/c5/05/c214b32d21c0b465506f95c4f28ccbcba15022e000b043b72b3df7728471/urllib3-1.26.16-py2.py3-none-any.whl.metadata\n",
      "  Using cached urllib3-1.26.16-py2.py3-none-any.whl.metadata (48 kB)\n",
      "Collecting typing-extensions>=4.2.0 (from pydantic==1.10.12)\n",
      "  Obtaining dependency information for typing-extensions>=4.2.0 from https://files.pythonhosted.org/packages/ec/6b/63cc3df74987c36fe26157ee12e09e8f9db4de771e0f3404263117e75b95/typing_extensions-4.7.1-py3-none-any.whl.metadata\n",
      "  Using cached typing_extensions-4.7.1-py3-none-any.whl.metadata (3.1 kB)\n",
      "Collecting s3transfer<0.7.0,>=0.6.0 (from boto3==1.28.21)\n",
      "  Obtaining dependency information for s3transfer<0.7.0,>=0.6.0 from https://files.pythonhosted.org/packages/d9/17/a3b666f5ef9543cfd3c661d39d1e193abb9649d0cfbbfee3cf3b51d5af02/s3transfer-0.6.2-py3-none-any.whl.metadata\n",
      "  Using cached s3transfer-0.6.2-py3-none-any.whl.metadata (1.8 kB)\n",
      "Using cached pydantic-1.10.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "Using cached typing_extensions-4.7.1-py3-none-any.whl (33 kB)\n",
      "Collecting six>=1.5 (from python-dateutil<3.0.0,>=2.1->botocore==1.31.21)\n",
      "  Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Using cached s3transfer-0.6.2-py3-none-any.whl (79 kB)\n",
      "Using cached urllib3-1.26.16-py2.py3-none-any.whl (143 kB)\n",
      "Installing collected packages: urllib3, six, jmespath, python-dateutil, botocore, s3transfer, boto3\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.26.16\n",
      "Installing collected packages: typing-extensions, pydantic\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Uninstalling urllib3-1.26.16:\n",
      "      Successfully uninstalled urllib3-1.26.16\n",
      "    Found existing installation: typing_extensions 4.7.1\n",
      "    Uninstalling typing_extensions-4.7.1:\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.16.0\n",
      "    Uninstalling six-1.16.0:\n",
      "      Successfully uninstalled six-1.16.0\n",
      "  Attempting uninstall: jmespath\n",
      "    Found existing installation: jmespath 1.0.1\n",
      "    Uninstalling jmespath-1.0.1:\n",
      "      Successfully uninstalled jmespath-1.0.1\n",
      "      Successfully uninstalled typing_extensions-4.7.1\n",
      "  Attempting uninstall: python-dateutil\n",
      "    Found existing installation: python-dateutil 2.8.2\n",
      "    Uninstalling python-dateutil-2.8.2:\n",
      "      Successfully uninstalled python-dateutil-2.8.2\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 1.10.12\n",
      "    Uninstalling pydantic-1.10.12:\n",
      "      Successfully uninstalled pydantic-1.10.12\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.31.21\n",
      "    Uninstalling botocore-1.31.21:\n",
      "      Successfully uninstalled botocore-1.31.21\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spyder 5.3.3 requires pyqt5<5.16, which is not installed.\n",
      "spyder 5.3.3 requires pyqtwebengine<5.16, which is not installed.\n",
      "panel 0.13.1 requires bokeh<2.5.0,>=2.4.0, but you have bokeh 3.2.1 which is incompatible.\n",
      "spyder 5.3.3 requires ipython<8.0.0,>=7.31.1, but you have ipython 8.14.0 which is incompatible.\n",
      "spyder 5.3.3 requires pylint<3.0,>=2.5.0, but you have pylint 3.0.0a6 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed pydantic-1.10.12 typing-extensions-4.7.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pydantic==1.10.12 --force-reinstall "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "123e83f2-1ab2-4fc3-a120-5d084fe7f140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Attempting uninstall: s3transfer\n",
      "    Found existing installation: s3transfer 0.6.2\n",
      "    Uninstalling s3transfer-0.6.2:\n",
      "      Successfully uninstalled s3transfer-0.6.2\n",
      "  Attempting uninstall: boto3\n",
      "    Found existing installation: boto3 1.28.21\n",
      "    Uninstalling boto3-1.28.21:\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -3transfer (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m      Successfully uninstalled boto3-1.28.21\n",
      "Successfully installed boto3-1.28.21 botocore-1.31.21 jmespath-1.0.1 python-dateutil-2.8.2 s3transfer-0.6.2 six-1.16.0 urllib3-1.26.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spyder 5.3.3 requires pyqt5<5.16, which is not installed.\n",
      "spyder 5.3.3 requires pyqtwebengine<5.16, which is not installed.\n",
      "awscli 1.29.14 requires botocore==1.31.14, but you have botocore 1.31.21 which is incompatible.\n",
      "distributed 2022.7.0 requires tornado<6.2,>=6.0.3, but you have tornado 6.3.2 which is incompatible.\n",
      "jupyterlab 3.4.4 requires jupyter-server~=1.16, but you have jupyter-server 2.7.0 which is incompatible.\n",
      "jupyterlab-server 2.10.3 requires jupyter-server~=1.4, but you have jupyter-server 2.7.0 which is incompatible.\n",
      "notebook 6.5.5 requires jupyter-client<8,>=5.3.4, but you have jupyter-client 8.3.0 which is incompatible.\n",
      "notebook 6.5.5 requires pyzmq<25,>=17, but you have pyzmq 25.1.0 which is incompatible.\n",
      "panel 0.13.1 requires bokeh<2.5.0,>=2.4.0, but you have bokeh 3.2.1 which is incompatible.\n",
      "sagemaker-datawrangler 0.4.3 requires sagemaker-data-insights==0.4.0, but you have sagemaker-data-insights 0.3.3 which is incompatible.\n",
      "spyder 5.3.3 requires ipython<8.0.0,>=7.31.1, but you have ipython 8.14.0 which is incompatible.\n",
      "spyder 5.3.3 requires pylint<3.0,>=2.5.0, but you have pylint 3.0.0a6 which is incompatible.\n",
      "spyder-kernels 2.3.3 requires ipython<8,>=7.31.1; python_version >= \"3\", but you have ipython 8.14.0 which is incompatible.\n",
      "spyder-kernels 2.3.3 requires jupyter-client<8,>=7.3.4; python_version >= \"3\", but you have jupyter-client 8.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain==0.0.266\n",
      "  Obtaining dependency information for langchain==0.0.266 from https://files.pythonhosted.org/packages/20/bf/976db78bec94a810375d3eb7fab5501ef774993da5f54947d5ba71efc997/langchain-0.0.266-py3-none-any.whl.metadata\n",
      "  Using cached langchain-0.0.266-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting pypdf==3.15.2\n",
      "  Obtaining dependency information for pypdf==3.15.2 from https://files.pythonhosted.org/packages/7e/19/d90c9a6b187df41a0136c8effdede51a63ed23c0be80f9792f042c992df8/pypdf-3.15.2-py3-none-any.whl.metadata\n",
      "  Using cached pypdf-3.15.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting llama-index==0.8.8\n",
      "  Obtaining dependency information for llama-index==0.8.8 from https://files.pythonhosted.org/packages/95/02/3ba91f40e7eed449158f2aaba47cbfa0f81e9525ccc5c0d4816302662593/llama_index-0.8.8-py3-none-any.whl.metadata\n",
      "  Using cached llama_index-0.8.8-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting sentence_transformers==2.2.2\n",
      "  Using cached sentence_transformers-2.2.2-py3-none-any.whl\n",
      "Collecting PyYAML>=5.3 (from langchain==0.0.266)\n",
      "  Obtaining dependency information for PyYAML>=5.3 from https://files.pythonhosted.org/packages/29/61/bf33c6c85c55bc45a29eee3195848ff2d518d84735eb0e2d8cb42e0d285e/PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain==0.0.266)\n",
      "  Obtaining dependency information for SQLAlchemy<3,>=1.4 from https://files.pythonhosted.org/packages/9f/94/8a20e0b867857cacf7e1269efc02aa81866071df844a2598fa34245a50df/SQLAlchemy-2.0.20-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached SQLAlchemy-2.0.20-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.4 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain==0.0.266)\n",
      "  Obtaining dependency information for aiohttp<4.0.0,>=3.8.3 from https://files.pythonhosted.org/packages/3e/f6/fcda07dd1e72260989f0b22dde999ecfe80daa744f23ca167083683399bc/aiohttp-3.8.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached aiohttp-3.8.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting async-timeout<5.0.0,>=4.0.0 (from langchain==0.0.266)\n",
      "  Obtaining dependency information for async-timeout<5.0.0,>=4.0.0 from https://files.pythonhosted.org/packages/a7/fa/e01228c2938de91d47b307831c62ab9e4001e747789d0b05baf779a6488c/async_timeout-4.0.3-py3-none-any.whl.metadata\n",
      "  Using cached async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting dataclasses-json<0.6.0,>=0.5.7 (from langchain==0.0.266)\n",
      "  Obtaining dependency information for dataclasses-json<0.6.0,>=0.5.7 from https://files.pythonhosted.org/packages/97/5f/e7cc90f36152810cab08b6c9c1125e8bcb9d76f8b3018d101b5f877b386c/dataclasses_json-0.5.14-py3-none-any.whl.metadata\n",
      "  Using cached dataclasses_json-0.5.14-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting langsmith<0.1.0,>=0.0.21 (from langchain==0.0.266)\n",
      "  Obtaining dependency information for langsmith<0.1.0,>=0.0.21 from https://files.pythonhosted.org/packages/94/af/c01937934a8d6e5e4f620a9c6013dc8b0d1a9f02a2a183761426f5ea67b6/langsmith-0.0.26-py3-none-any.whl.metadata\n",
      "  Using cached langsmith-0.0.26-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting numexpr<3.0.0,>=2.8.4 (from langchain==0.0.266)\n",
      "  Obtaining dependency information for numexpr<3.0.0,>=2.8.4 from https://files.pythonhosted.org/packages/57/c7/eb746d20c1a3c85ef6e4743e9e61d1ff8709bea3b28da64100e848c10fdb/numexpr-2.8.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached numexpr-2.8.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.0 kB)\n",
      "Collecting numpy<2,>=1 (from langchain==0.0.266)\n",
      "  Obtaining dependency information for numpy<2,>=1 from https://files.pythonhosted.org/packages/71/3c/3b1981c6a1986adc9ee7db760c0c34ea5b14ac3da9ecfcf1ea2a4ec6c398/numpy-1.25.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached numpy-1.25.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "Collecting openapi-schema-pydantic<2.0,>=1.2 (from langchain==0.0.266)\n",
      "  Using cached openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n",
      "Collecting pydantic<2,>=1 (from langchain==0.0.266)\n",
      "  Obtaining dependency information for pydantic<2,>=1 from https://files.pythonhosted.org/packages/bc/e0/0371e9b6c910afe502e5fe18cc94562bfd9399617c7b4f5b6e13c29115b3/pydantic-1.10.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached pydantic-1.10.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (149 kB)\n",
      "Collecting requests<3,>=2 (from langchain==0.0.266)\n",
      "  Obtaining dependency information for requests<3,>=2 from https://files.pythonhosted.org/packages/70/8e/0e2d847013cb52cd35b38c009bb167a1a26b2ce6cd6965bf26b47bc0bf44/requests-2.31.0-py3-none-any.whl.metadata\n",
      "  Using cached requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tenacity<9.0.0,>=8.1.0 (from langchain==0.0.266)\n",
      "  Obtaining dependency information for tenacity<9.0.0,>=8.1.0 from https://files.pythonhosted.org/packages/f4/f1/990741d5bb2487d529d20a433210ffa136a367751e454214013b441c4575/tenacity-8.2.3-py3-none-any.whl.metadata\n",
      "  Using cached tenacity-8.2.3-py3-none-any.whl.metadata (1.0 kB)\n",
      "Collecting tiktoken (from llama-index==0.8.8)\n",
      "  Using cached tiktoken-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "Collecting openai>=0.26.4 (from llama-index==0.8.8)\n",
      "  Obtaining dependency information for openai>=0.26.4 from https://files.pythonhosted.org/packages/a0/19/7e39855c63b68ef15b1c2c9e4d941026fb0c94940979e161bb5b470f8455/openai-0.27.9-py3-none-any.whl.metadata\n",
      "  Using cached openai-0.27.9-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pandas (from llama-index==0.8.8)\n",
      "  Obtaining dependency information for pandas from https://files.pythonhosted.org/packages/e3/59/35a2892bf09ded9c1bf3804461efe772836a5261ef5dfb4e264ce813ff99/pandas-2.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached pandas-2.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting urllib3<2 (from llama-index==0.8.8)\n",
      "  Obtaining dependency information for urllib3<2 from https://files.pythonhosted.org/packages/c5/05/c214b32d21c0b465506f95c4f28ccbcba15022e000b043b72b3df7728471/urllib3-1.26.16-py2.py3-none-any.whl.metadata\n",
      "  Using cached urllib3-1.26.16-py2.py3-none-any.whl.metadata (48 kB)\n",
      "Collecting fsspec>=2023.5.0 (from llama-index==0.8.8)\n",
      "  Obtaining dependency information for fsspec>=2023.5.0 from https://files.pythonhosted.org/packages/e3/bd/4c0a4619494188a9db5d77e2100ab7d544a42e76b2447869d8e124e981d8/fsspec-2023.6.0-py3-none-any.whl.metadata\n",
      "  Using cached fsspec-2023.6.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting typing-inspect>=0.8.0 (from llama-index==0.8.8)\n",
      "  Obtaining dependency information for typing-inspect>=0.8.0 from https://files.pythonhosted.org/packages/65/f3/107a22063bf27bdccf2024833d3445f4eea42b2e598abfbd46f6a63b6cb0/typing_inspect-0.9.0-py3-none-any.whl.metadata\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting typing-extensions>=4.5.0 (from llama-index==0.8.8)\n",
      "  Obtaining dependency information for typing-extensions>=4.5.0 from https://files.pythonhosted.org/packages/ec/6b/63cc3df74987c36fe26157ee12e09e8f9db4de771e0f3404263117e75b95/typing_extensions-4.7.1-py3-none-any.whl.metadata\n",
      "  Using cached typing_extensions-4.7.1-py3-none-any.whl.metadata (3.1 kB)\n",
      "Collecting beautifulsoup4 (from llama-index==0.8.8)\n",
      "  Using cached beautifulsoup4-4.12.2-py3-none-any.whl (142 kB)\n",
      "Collecting nest-asyncio (from llama-index==0.8.8)\n",
      "  Obtaining dependency information for nest-asyncio from https://files.pythonhosted.org/packages/7e/dd/69a7a6e89bb1fe09f99bde22027154c487b1e8b6769e642d7f56f35696d3/nest_asyncio-1.5.7-py3-none-any.whl.metadata\n",
      "  Using cached nest_asyncio-1.5.7-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting transformers<5.0.0,>=4.6.0 (from sentence_transformers==2.2.2)\n",
      "  Obtaining dependency information for transformers<5.0.0,>=4.6.0 from https://files.pythonhosted.org/packages/ae/95/283a1c004430bd2a9425d6937fc545dd49a4e4592feb76be0299a14e2378/transformers-4.32.0-py3-none-any.whl.metadata\n",
      "  Using cached transformers-4.32.0-py3-none-any.whl.metadata (118 kB)\n",
      "Collecting tqdm (from sentence_transformers==2.2.2)\n",
      "  Obtaining dependency information for tqdm from https://files.pythonhosted.org/packages/00/e5/f12a80907d0884e6dff9c16d0c0114d81b8cd07dc3ae54c5e962cc83037e/tqdm-4.66.1-py3-none-any.whl.metadata\n",
      "  Using cached tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting torch>=1.6.0 (from sentence_transformers==2.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# langchain==0.0.266 is required by llama-index==0.8.8\n",
    "%pip install langchain==0.0.266 \\\n",
    "    pypdf==3.15.2 \\\n",
    "    llama-index==0.8.8 \\\n",
    "    sentence_transformers==2.2.2 --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab68a3ee-f4c1-4830-856a-9c37f7a42364",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c16404b-db81-4ee6-9c0f-cc4cdf3cb147",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from llama_index import (\n",
    "    VectorStoreIndex,\n",
    "    SimpleDirectoryReader,\n",
    "    ServiceContext,\n",
    "    LLMPredictor,\n",
    "    get_response_synthesizer,\n",
    "    set_global_service_context,\n",
    "    StorageContext,\n",
    "    ListIndex\n",
    ")\n",
    "from llama_index.indices.postprocessor import LLMRerank\n",
    "from llama_index.llms import OpenAI\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce8809c-b174-4970-8758-f867cf968d81",
   "metadata": {},
   "source": [
    "### Setup langchain and llama index\n",
    "\n",
    "In this step we will be creating of instance for LLM and embedding models. We will be using Claude and Titan models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0514e54-36cd-4faf-b824-4cce34177bbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index import LangchainEmbedding\n",
    "from langchain.llms.bedrock import Bedrock \n",
    "from langchain.embeddings.bedrock import BedrockEmbeddings\n",
    "\n",
    "model_kwargs_titan = { \n",
    "        \"maxTokenCount\": 512,\n",
    "        \"stopSequences\": [],\n",
    "        \"temperature\":0.0,  \n",
    "        \"topP\":0.5\n",
    "    }\n",
    "\n",
    "llm = Bedrock(model_id=\"amazon.titan-tg1-large\",\n",
    "              model_kwargs=model_kwargs_titan)\n",
    "\n",
    "embed_model = LangchainEmbedding(\n",
    "    BedrockEmbeddings(model_id=\"amazon.titan-e1t-medium\")\n",
    ")\n",
    "\n",
    "service_context = ServiceContext.from_defaults(llm=llm, \n",
    "                                               embed_model=embed_model, \n",
    "                                               chunk_size=512)\n",
    "set_global_service_context(service_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb2f25b-2d06-42c7-8d65-9fd2c063ed81",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3491600b-32fa-4559-8d25-c7d07a57b84b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p ./data\n",
    "\n",
    "from urllib.request import urlretrieve\n",
    "urls = [\n",
    "    'https://s2.q4cdn.com/299287126/files/doc_financials/2023/ar/2022-Shareholder-Letter.pdf',\n",
    "    'https://s2.q4cdn.com/299287126/files/doc_financials/2022/ar/2021-Shareholder-Letter.pdf',\n",
    "    'https://s2.q4cdn.com/299287126/files/doc_financials/2021/ar/Amazon-2020-Shareholder-Letter-and-1997-Shareholder-Letter.pdf',\n",
    "    'https://s2.q4cdn.com/299287126/files/doc_financials/2020/ar/2019-Shareholder-Letter.pdf'\n",
    "]\n",
    "\n",
    "filenames = [\n",
    "    'AMZN-2022-Shareholder-Letter.pdf',\n",
    "    'AMZN-2021-Shareholder-Letter.pdf',\n",
    "    'AMZN-2020-Shareholder-Letter.pdf',\n",
    "    'AMZN-2019-Shareholder-Letter.pdf'\n",
    "]\n",
    "\n",
    "metadata = [\n",
    "    dict(year=2022, source=filenames[0]),\n",
    "    dict(year=2021, source=filenames[1]),\n",
    "    dict(year=2020, source=filenames[2]),\n",
    "    dict(year=2019, source=filenames[3])]\n",
    "\n",
    "data_root = \"./data/\"\n",
    "\n",
    "for idx, url in enumerate(urls):\n",
    "    file_path = data_root + filenames[idx]\n",
    "    urlretrieve(url, file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61931154-fabf-41f2-8c1a-f7db4df8d304",
   "metadata": {},
   "source": [
    "As part of Amazon's culture, the CEO always includes a copy of the 1997 Letter to Shareholders with every new release. This will cause repetition, take longer to generate embeddings, and may skew your results. In the next section you will take the downloaded data, trim the 1997 letter (last 3 pages) and overwrite them as processed files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91a0b300-0c6c-43be-a2ea-ae16fa0912f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "from pypdf import PdfReader, PdfWriter\n",
    "\n",
    "local_pdfs = glob.glob(data_root + '*.pdf')\n",
    "\n",
    "for local_pdf in local_pdfs:\n",
    "    pdf_reader = PdfReader(local_pdf)\n",
    "    pdf_writer = PdfWriter()\n",
    "    for pagenum in range(len(pdf_reader.pages)-3):\n",
    "        page = pdf_reader.pages[pagenum]\n",
    "        pdf_writer.add_page(page)\n",
    "\n",
    "    with open(local_pdf, 'wb') as new_file:\n",
    "        new_file.seek(0)\n",
    "        pdf_writer.write(new_file)\n",
    "        new_file.truncate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0feafd-12ef-40b4-9bb4-99ff7bc8bac9",
   "metadata": {},
   "source": [
    "Now that you have clean PDFs to work with, you will enrich your documents with metadata, then use a process called \"chunking\" to break up a larger document into small pieces. These small pieces will allow you to generate embeddings without surpassing the input limit of the embedding model.\n",
    "\n",
    "In this example you will break the document into 1000 character chunks, with a 100 character overlap. This will allow your embeddings to maintain some of its context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4429b839-e244-42b8-9b24-5368c1bb0a21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "docs = []\n",
    "for filename in filenames:\n",
    "    doc = SimpleDirectoryReader(input_files=[f\"data/{filename}\"]).load_data()\n",
    "    doc[0].doc_id = filename.replace(\".pdf\", \"\")\n",
    "    docs.extend(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41704f08-d210-4c7e-aa03-f3f8c48252e8",
   "metadata": {},
   "source": [
    "### Build Document Summary Index\n",
    "\n",
    "We show two ways of building the index:\n",
    "- default mode of building the document summary index\n",
    "- customizing the summary query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a3004bc-c525-4b57-aebd-b0d38b3a8cc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### Un comment the following lines to run from your local environment outside of the AWS account with Bedrock access\n",
    "\n",
    "#import os\n",
    "#os.environ['BEDROCK_ASSUME_ROLE'] = '<YOUR_VALUES>'\n",
    "#os.environ['AWS_PROFILE'] = 'bedrock-user'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d56ea0a6-7563-4005-a573-10ce0ebbc0de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create new client\n",
      "  Using region: us-west-2\n",
      "boto3 Bedrock client successfully created!\n",
      "bedrock(https://bedrock.us-west-2.amazonaws.com)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import boto3\n",
    "import json\n",
    "import sys\n",
    "\n",
    "module_path = \"..\"\n",
    "sys.path.append(os.path.abspath(module_path))\n",
    "from utils import bedrock, print_ww\n",
    "\n",
    "os.environ['AWS_DEFAULT_REGION'] = 'us-west-2'\n",
    "boto3_bedrock = bedrock.get_bedrock_client(os.environ.get('BEDROCK_ASSUME_ROLE', None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c912e31-a44b-4a65-b75f-212413865acd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '37ef4a35-d74a-48a2-86ea-8012ccffaeb3',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'date': 'Thu, 24 Aug 2023 04:50:12 GMT',\n",
       "   'content-type': 'application/json',\n",
       "   'content-length': '1166',\n",
       "   'connection': 'keep-alive',\n",
       "   'x-amzn-requestid': '37ef4a35-d74a-48a2-86ea-8012ccffaeb3'},\n",
       "  'RetryAttempts': 0},\n",
       " 'modelSummaries': [{'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/amazon.titan-tg1-large',\n",
       "   'modelId': 'amazon.titan-tg1-large'},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/amazon.titan-e1t-medium',\n",
       "   'modelId': 'amazon.titan-e1t-medium'},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/stability.stable-diffusion-xl',\n",
       "   'modelId': 'stability.stable-diffusion-xl'},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/ai21.j2-grande-instruct',\n",
       "   'modelId': 'ai21.j2-grande-instruct'},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/ai21.j2-jumbo-instruct',\n",
       "   'modelId': 'ai21.j2-jumbo-instruct'},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/ai21.j2-mid',\n",
       "   'modelId': 'ai21.j2-mid'},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/ai21.j2-ultra',\n",
       "   'modelId': 'ai21.j2-ultra'},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/anthropic.claude-instant-v1',\n",
       "   'modelId': 'anthropic.claude-instant-v1'},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/anthropic.claude-v1',\n",
       "   'modelId': 'anthropic.claude-v1'},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/anthropic.claude-v2',\n",
       "   'modelId': 'anthropic.claude-v2'}]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boto3_bedrock.list_foundation_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8555b6d-5289-4803-bced-6b2f85dea3da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "index = VectorStoreIndex.from_documents(docs,\n",
    "    service_context=service_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9ba68d6-3a91-4b31-a8b9-b7cc6d33b5f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nodes = service_context.node_parser.get_nodes_from_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a413a570-686c-4865-a424-7f69b822b640",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# initialize storage context (by default it's in-memory)\n",
    "storage_context = StorageContext.from_defaults()\n",
    "storage_context.docstore.add_documents(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805847d9-a2c1-4930-98a9-98126e730000",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ace86835-832e-4964-a025-428891aa2c8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.retrievers import VectorIndexRetriever\n",
    "from llama_index.indices.query.schema import QueryBundle\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "def get_retrieved_nodes(\n",
    "    query_str, vector_top_k=10, reranker_top_n=3, with_reranker=False\n",
    "):\n",
    "    query_bundle = QueryBundle(query_str)\n",
    "    # configure retriever\n",
    "    retriever = VectorIndexRetriever(\n",
    "        index=index,\n",
    "        similarity_top_k=vector_top_k\n",
    "\n",
    "    )\n",
    "    retrieved_nodes = retriever.retrieve(query_bundle)\n",
    "\n",
    "    if with_reranker:\n",
    "        # configure reranker\n",
    "        reranker = LLMRerank(\n",
    "            choice_batch_size=5, \n",
    "            top_n=reranker_top_n, \n",
    "            service_context=service_context\n",
    "        )\n",
    "        retrieved_nodes = reranker.postprocess_nodes(retrieved_nodes, query_bundle)\n",
    "\n",
    "    return retrieved_nodes\n",
    "\n",
    "\n",
    "def pretty_print(df):\n",
    "    return display(HTML(df.to_html().replace(\"\\\\n\", \"<br>\")))\n",
    "\n",
    "\n",
    "def visualize_retrieved_nodes(nodes) -> None:\n",
    "    result_dicts = []\n",
    "    for node in nodes:\n",
    "        result_dict = {\"Score\": node.score, \"Text\": node.node.get_text()}\n",
    "        result_dicts.append(result_dict)\n",
    "\n",
    "    pretty_print(pd.DataFrame(result_dicts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57492945-9ac6-44d9-9588-d6f97a460b0c",
   "metadata": {},
   "source": [
    "Now, we will showcase how to do a two-stage pass for retrieval. Use embedding-based retrieval with a high top-k value in order to maximize recall and get a large set of candidate items. Then, use LLM-based retrieval to dynamically select the nodes that are actually relevant to the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "20993200-b725-403e-8a79-e2571dab2ebc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "retrieved_nodes1 = get_retrieved_nodes(\n",
    "    \"How has AWS evolved?\", vector_top_k=3, with_reranker=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c65220b0-ce3d-4bfb-a409-35d7cc035a61",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(retrieved_nodes1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9dd3bc25-6ef1-46b7-869e-247c83af9d4d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6064377194306085\n",
      "Everybody agreed that having a persistent block store was important to a complete compute service;\n",
      "however, to have one ready would take an extra year.The question became could we offer customers auseful service where they could get meaningful value before we had all the features we thought they wanted?We decided that the initial launch of EC2 could be feature-poor if we also organized ourselves to listen tocustomers and iterate quickly.This approach works well if you indeed iterate quickly; but, is disastrous if youcan’t.We launched EC2 in 2006 with one instance size, in one data center, in one region of the world, withLinux operating system instances only (no Windows), without monitoring, load balancing, auto-scaling, oryes, persistent storage.EC2 was an initial success, but nowhere near the multi-billion-dollar service it’sbecome until we added the missing capabilities listed above, and then some.In the early days of AWS, people sometimes asked us why compute wouldn’t just be an undifferentiated\n",
      "commodity.But, there’s a lot more to compute than just a server.Customers want various flavors of compute(e.g.server configurations optimized for storage, memory, high-performance compute, graphics rendering,machine learning), multiple form factors (e.g.fixed instance sizes, portable containers, serverless functions),various sizes and optimizations of persistent storage, and a slew of networking capabilities.Then, there’sthe CPU chip that runs in your compute.For many years, the industry had used Intel or AMD x86 processors.We have important partnerships with these companies, but realized that if we wanted to push price andperformance further (as customers requested), we’d have to develop our own chips, too.Our first generalizedchip was Graviton, which we announced in 2018.This helped a subset of customer workloads run morecost-effectively than prior options.But, it wasn’t until 2020, after taking the learnings from Graviton and\n",
      "innovating on a new chip, that we had something remarkable with our Graviton2 chip, which provides up to40% better price-performance than the comparable latest generation x86 processors.Think about howmuch of an impact 40% improvement on compute is.Compute is used for every bit of technology.\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "0.5872555486424139\n",
      "AWS : As we were defining AWS and working backwards on the services we thought customers wanted, we\n",
      "kept triggering one of the biggest tensions in product development—where to draw the line on functionality inV1.One early meeting in particular—for our core compute service called Elastic Compute Cloud (“EC2”)—was scheduled for an hour, and took three, as we animatedly debated whether we could launch a computeservice without an accompanying persistent block storage companion (a form of network attached storage).\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "0.5382687939125778\n",
      "That’s ahuge deal for customers.And, while Graviton2 has been a significant success thus far (48 of the top 50 AWSEC2 customers have already adopted it), the AWS Chips team was already learning from what customerssaid could be better, and announced Graviton3 this past December (offering a 25% improvement on top ofGraviton2’s relative gains).The list of what we’ve invented and delivered for customers in EC2 (and AWS ingeneral) is pretty mind-boggling, and this iterative approach to innovation has not only given customersmuch more functionality in AWS than they can find anywhere else (which is a significant differentiator), butalso allowed us to arrive at the much more game-changing offering that AWS is today.Devices : Our first foray into devices was the Kindle, released in 2007.It was not the most sophisticated\n",
      "industrial design (it was creamy white in color and the corners were uncomfortable for some people to hold),but revolutionary because it offered customers the ability to download any of over 90,000 books (nowmillions) in 60 seconds—and we got better and faster at building attractive designs.Shortly thereafter, welaunched a tablet, and then a phone (with the distinguishing feature of having front-facing cameras and agyroscope to give customers a dynamic perspective along with varied 3D experiences).The phone wasunsuccessful, and though we determined we were probably too late to this party and directed these resourceselsewhere, we hired some fantastic long-term builders and learned valuable lessons from this failure thathave served us well in devices like Echo and FireTV .When I think of the first Echo device—and what Alexa could do for customers at that point—it was\n",
      "noteworthy, yet so much less capable than what’s possible today.\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i, node in enumerate(retrieved_nodes1):\n",
    "    print(node.score)\n",
    "    print(node.node.get_text())\n",
    "    print(\"-----------------------------------------------------------------------------------------------------------------------------------\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0ad7d62b-dba9-45d5-896f-4baa9a40edba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "retrieved_nodes1_withreranker = get_retrieved_nodes(\n",
    "    \"How has AWS evolved?\",\n",
    "    vector_top_k=3,\n",
    "    reranker_top_n=1,\n",
    "    with_reranker=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8d031c16-16ac-425e-ad56-3b9ef0dd0fea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(retrieved_nodes1_withreranker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ae22d297-dd3b-4a71-a890-faceafab4e1a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0\n",
      "Everybody agreed that having a persistent block store was important to a complete compute service;\n",
      "however, to have one ready would take an extra year.The question became could we offer customers auseful service where they could get meaningful value before we had all the features we thought they wanted?We decided that the initial launch of EC2 could be feature-poor if we also organized ourselves to listen tocustomers and iterate quickly.This approach works well if you indeed iterate quickly; but, is disastrous if youcan’t.We launched EC2 in 2006 with one instance size, in one data center, in one region of the world, withLinux operating system instances only (no Windows), without monitoring, load balancing, auto-scaling, oryes, persistent storage.EC2 was an initial success, but nowhere near the multi-billion-dollar service it’sbecome until we added the missing capabilities listed above, and then some.In the early days of AWS, people sometimes asked us why compute wouldn’t just be an undifferentiated\n",
      "commodity.But, there’s a lot more to compute than just a server.Customers want various flavors of compute(e.g.server configurations optimized for storage, memory, high-performance compute, graphics rendering,machine learning), multiple form factors (e.g.fixed instance sizes, portable containers, serverless functions),various sizes and optimizations of persistent storage, and a slew of networking capabilities.Then, there’sthe CPU chip that runs in your compute.For many years, the industry had used Intel or AMD x86 processors.We have important partnerships with these companies, but realized that if we wanted to push price andperformance further (as customers requested), we’d have to develop our own chips, too.Our first generalizedchip was Graviton, which we announced in 2018.This helped a subset of customer workloads run morecost-effectively than prior options.But, it wasn’t until 2020, after taking the learnings from Graviton and\n",
      "innovating on a new chip, that we had something remarkable with our Graviton2 chip, which provides up to40% better price-performance than the comparable latest generation x86 processors.Think about howmuch of an impact 40% improvement on compute is.Compute is used for every bit of technology.\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i, node in enumerate(retrieved_nodes1_withreranker):\n",
    "    print(node.score)\n",
    "    print(node.node.get_text())\n",
    "    print(\"-----------------------------------------------------------------------------------------------------------------------------------\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7033d487-3b31-4c95-9a63-afec75e3bc37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "retrieved_nodes2 = get_retrieved_nodes(\n",
    "    \"Human: Why is Amazon successful?\", vector_top_k=3, with_reranker=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "444a3658-740c-4efa-b73d-d102528ddf8a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(retrieved_nodes2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "104633ac-d7ee-496d-8c4b-44aa462098f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6096547344564625\n",
      "through the pandemic the same way without the dedication and extraordinary efforts shown by our teams\n",
      "during this period, and I’m eternally grateful.It’s not normal for a company of any size to be able to respond to something as discontinuous and\n",
      "unpredictable as this pandemic turned out to be.What is it about Amazon that made it possible for us to doso?It’s because we weren’t starting from a standing start.We had been iterating on and remaking ourfulfillment capabilities for nearly two decades.In every business we pursue, we’re constantly experimentingand inventing.We’re divinely discontented with customer experiences, whether they’re our own or not.Webelieve these customer experiences can always be better, and we strive to make customers’ lives better andeasier every day.The beauty of this mission is that you never run out of runway; customers always want better,and our job is both to listen to their feedback and to imagine what else is possible and invent on theirbehalf.People often assume that the game-changing inventions they admire just pop out of somebody’s head, a\n",
      "light bulb goes off, a team executes to that idea, and presto—you have a new invention that’s a breakawaysuccess for a long time.That’s rarely, if ever, how it happens.One of the lesser known facts about innovativecompanies like Amazon is that they are relentlessly debating, re-defining, tinkering, iterating, andexperimenting to take the seed of a big idea and make it into something that resonates with customers andmeaningfully changes their customer experience over a long period of time.Let me give you some Amazon examples.Our Fulfillment Network : Going back to the pandemic, there’s no way we could have started working on\n",
      "our fulfillment network in March 2020 and satisfied anything close to what our customers needed.We’d beeninnovating in our fulfillment network for 20 years, constantly trying to shorten the time to get items to\n",
      "customers.In the early 2000s, it took us an average of 18 hours to get an item through our fulfillment centersand on the right truck for shipment.Now, it takes us two.\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "0.55290102791834\n",
      "I could have given comparable\n",
      "examples in Advertising, Grocery, Gaming, Amazon Music, Amazon Care (our telemedicine offering), orPharmacy, to name a few.All of these stories are still being written as we rapidly experiment, learn, andcontinue to try to make our customer experience better every day.If this approach sounds appealing, a natural question is what’s required to get good at it?It’s easier said\n",
      "than done, but here are some components that have helped us:\n",
      "1/Hire the Right Builders : We disproportionately index in hiring builders.We think of builders as people\n",
      "who like to invent, who look at customer experiences, dissect what doesn’t work well about them, and seekto reinvent them.We want people who keep asking why can’t it be done?We want people who like toexperiment and tinker, and who realize launch is the starting line, not the finish line.2/Organize Builders into Teams That Are as Separable and Autonomous as Possible : It’s hard for teams to be\n",
      "deep in what customers care about in multiple areas.It’s also hard to spend enough time on the newinitiatives when there’s resource contention with the more mature businesses; the surer bets usually win out.Single-threaded teams will know their customers’ needs better, spend all their waking work hours inventingfor them, and develop context and tempo to keep iterating quickly.3/Give Teams the Right Tools and Permission to Move Fast : Speed is not pre-ordained.It’s a leadership\n",
      "choice.It has trade-offs, but you can’t wake up one day and start moving fast.It requires having the righttools to experiment and build fast (a major part of why we started AWS), allowing teams to make two-waydoor decisions themselves, and setting an expectation that speed matters.And, it does.Speed isdisproportionally important to every business at every stage of its evolution.Those that move slower thantheir competitive peers fall away over time.4/You Need Blind Faith, But No False Hope : This is a lyric from one of my favorite Foo Fighters songs\n",
      "(“Congregation”).\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "0.5367685340979536\n",
      "Why?Because the team has translated what it means to deliver selection, value, and convenience into a businessprocurement setting, constantly listening to and learning from customers, and innovating on their behalf.Some people have never heard of Amazon Business, but, our business customers love it.Amazon Businesslaunched in 2015 and today drives roughly $35B in annualized gross sales.More than six million activecustomers, including 96 of the global Fortune 100 companies, are enjoying Amazon Business’ one-stopshopping, real-time analytics, and broad selection on hundreds of millions of business supplies.We believethat we’ve only scratched the surface of what’s possible to date, and plan to keep building the features ourbusiness customers tell us they need and want.While many brands and merchants successfully sell their products on Amazon’s marketplace, there are also\n",
      "a large number of brands and sellers who have launched their own direct-to-consumer websites.One of thechallenges for these merchants is driving conversion from views to purchases.We invented Buy with Prime\n",
      "to help with this challenge.Buy with Prime allows third-party brands and sellers to offer their products ontheir own websites to our large Amazon Prime membership, and offer those customers fast, free Prime shippingand seamless checkout with their Amazon account.Buy with Prime provides merchants several additionalbenefits, including Amazon handling the product storage, picking, packing, delivery, payment, and anyreturns, all through Amazon Pay and Fulfillment by Amazon.Buy with Prime has recently been madeavailable to all US merchants; and so far, Buy with Prime has increased shopper conversion on third-partyshopping sites by 25% on average.Merchants are excited about converting more sales and fulfilling theseshipments more easily, Prime members love that they can use their Prime benefits on more destinations,and Buy with Prime allows us to improve the shopping experience across more of the web.Expanding internationally, pursuing large retail market segments that are still nascent for Amazon, and\n",
      "using our unique assets to help merchants sell more effectively on their own websites are somewhat naturalextensions for us.There are also a few investments we’re making that are further from our core businesses, butwhere we see unique opportunity.In 2003, AWS would have been a classic example.\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i, node in enumerate(retrieved_nodes2):\n",
    "    print(node.score)\n",
    "    print(node.node.get_text())\n",
    "    print(\"-----------------------------------------------------------------------------------------------------------------------------------\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ab0acde8-cb0a-4fa8-b30f-4fc965d8e7f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "retrieved_nodes2_withreranker = get_retrieved_nodes(\n",
    "    \"Human: Why is Amazon successful?\",\n",
    "    vector_top_k=3,\n",
    "    reranker_top_n=1,\n",
    "    with_reranker=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e8ba718e-4ae9-4e15-8739-4f68f2d046b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(retrieved_nodes2_withreranker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "04678820-d492-4c4a-b246-04a10e7d6b6c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0\n",
      "through the pandemic the same way without the dedication and extraordinary efforts shown by our teams\n",
      "during this period, and I’m eternally grateful.It’s not normal for a company of any size to be able to respond to something as discontinuous and\n",
      "unpredictable as this pandemic turned out to be.What is it about Amazon that made it possible for us to doso?It’s because we weren’t starting from a standing start.We had been iterating on and remaking ourfulfillment capabilities for nearly two decades.In every business we pursue, we’re constantly experimentingand inventing.We’re divinely discontented with customer experiences, whether they’re our own or not.Webelieve these customer experiences can always be better, and we strive to make customers’ lives better andeasier every day.The beauty of this mission is that you never run out of runway; customers always want better,and our job is both to listen to their feedback and to imagine what else is possible and invent on theirbehalf.People often assume that the game-changing inventions they admire just pop out of somebody’s head, a\n",
      "light bulb goes off, a team executes to that idea, and presto—you have a new invention that’s a breakawaysuccess for a long time.That’s rarely, if ever, how it happens.One of the lesser known facts about innovativecompanies like Amazon is that they are relentlessly debating, re-defining, tinkering, iterating, andexperimenting to take the seed of a big idea and make it into something that resonates with customers andmeaningfully changes their customer experience over a long period of time.Let me give you some Amazon examples.Our Fulfillment Network : Going back to the pandemic, there’s no way we could have started working on\n",
      "our fulfillment network in March 2020 and satisfied anything close to what our customers needed.We’d beeninnovating in our fulfillment network for 20 years, constantly trying to shorten the time to get items to\n",
      "customers.In the early 2000s, it took us an average of 18 hours to get an item through our fulfillment centersand on the right truck for shipment.Now, it takes us two.\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i, node in enumerate(retrieved_nodes2_withreranker):\n",
    "    print(node.score)\n",
    "    print(node.node.get_text())\n",
    "    print(\"-----------------------------------------------------------------------------------------------------------------------------------\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109f0d82-a9e4-4736-824c-3223b21247c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
